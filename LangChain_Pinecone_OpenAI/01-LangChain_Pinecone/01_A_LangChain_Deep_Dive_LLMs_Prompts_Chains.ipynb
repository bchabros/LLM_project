{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e1476ee-4cac-4c75-939e-c6872292a6cc",
   "metadata": {},
   "source": [
    "# Deep Dive into LangChain\n",
    "## LLMs, Prompt Templates, Caching, Streaming, Chains\n",
    "\n",
    "This notebook uses the latest versions of the OpenAI and LangChain libraries."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ee9a618-d423-4cce-8e32-ed937698c0d5",
   "metadata": {},
   "source": [
    "### Python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e052148c-1dd2-4cd2-8878-fd90e58dabfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# loading the API Keys from .env\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "654afaf9-00bc-4d4d-99ab-907055d4139c",
   "metadata": {},
   "source": [
    "## Chat Models: GPT-3.5 Turbo and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2eb526e-4105-4301-b931-f285f258035b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum mechanics is the branch of physics that describes the behavior of particles at the smallest scales, where traditional laws of physics no longer apply and phenomena such as superposition and entanglement occur.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()  \n",
    "\n",
    "# invoking the llm (running the prompt)\n",
    "output = llm.invoke('Explain quantum mechanics in one sentence.', model='gpt-3.5-turbo', temperature=0.1)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54b5b306-6905-4c58-82ef-17cc9be9777d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# help(ChatOpenAI)  # see the llm constructor arguments with its defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2baa8e-8440-4c16-a1bb-91f8ff0ac556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantenmechanik beschreibt das Verhalten von Teilchen auf atomarer und subatomarer Ebene durch Wellenfunktionen und Wahrscheinlichkeitsverteilungen.\n"
     ]
    }
   ],
   "source": [
    "# using Chat Completions API Messages: System, Assistant and Human\n",
    "from langchain.schema import(\n",
    "    SystemMessage, \n",
    "    AIMessage,\n",
    "    HumanMessage\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content='You are a physicist and respond only in German.'),\n",
    "    HumanMessage(content='Explain quantum mechanics in one sentence.')\n",
    "]\n",
    "\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "919e837c-d307-4165-ad99-551a2bee6cf5",
   "metadata": {},
   "source": [
    "## Caching LLM Responses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7379171e-2081-4cc1-a834-89ebff34e84c",
   "metadata": {},
   "source": [
    "### 1. In-Memory Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a73a4e4-d351-4f4c-b149-151fe3b2c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(model_name='gpt-3.5-turbo-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d356c163-afd3-4534-9947-69e088f16913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20232db3-97a5-498e-805f-fbcb24d14584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 ms, sys: 2.18 ms, total: 19.7 ms\n",
      "Wall time: 934 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhy was the math book sad? Because it had too many problems!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prompt = 'Tell a me a joke that a toddler can understand.'\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d58e8e-c8b3-4719-b4ad-a3d03bfb7655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 373 µs, sys: 1e+03 ns, total: 374 µs\n",
      "Wall time: 379 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhy was the math book sad? Because it had too many problems!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6269939d-b92f-406a-a53f-9a7bf561c5a2",
   "metadata": {},
   "source": [
    "### 2. SQLite Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9271fe21-1ca3-4cb2-8599-9a368071482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a13f4281-b6c7-4a46-ab08-b02528f4111e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 ms, sys: 3.56 ms, total: 24.5 ms\n",
      "Wall time: 778 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nWhy couldn't the bicycle stand up by itself? Because it was two-tired!\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# First request (not in cache, takes longer)\n",
    "llm.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3fe8a61-0812-427b-bdae-06adc67988f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 60.6 ms, sys: 28.1 ms, total: 88.7 ms\n",
      "Wall time: 88 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nWhy couldn't the bicycle stand up by itself? Because it was two-tired!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Second request (cached, faster)\n",
    "llm.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f56aa044-5842-4d50-b3e9-0207421df1cf",
   "metadata": {},
   "source": [
    "## LLM Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "174adda0-ce4a-40bb-8a28-31abc494f266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verse 1:\n",
      "Beneath the silver light of the moon\n",
      "A raven flies high, singing a haunting tune\n",
      "Its wings black as night, against the pale sky\n",
      "A messenger of darkness, soaring up so high\n",
      "\n",
      "Chorus:\n",
      "Moon and raven, dance in the night\n",
      "Their spirits intertwined, forever in flight\n",
      "Whispers of mystery, in the cold night air\n",
      "Moon and raven, a timeless pair\n",
      "\n",
      "Verse 2:\n",
      "The moon watches over, with a steady gaze\n",
      "As the raven calls out, in a mysterious haze\n",
      "Their connection unbreakable, their bond so strong\n",
      "In the darkness of the night, they both belong\n",
      "\n",
      "Chorus:\n",
      "Moon and raven, dance in the night\n",
      "Their spirits intertwined, forever in flight\n",
      "Whispers of mystery, in the cold night air\n",
      "Moon and raven, a timeless pair\n",
      "\n",
      "Bridge:\n",
      "The raven croaks out a solemn cry\n",
      "Echoing through the night sky\n",
      "The moon shines down, a guiding light\n",
      "Together they soar, in the darkness of night\n",
      "\n",
      "Chorus:\n",
      "Moon and raven, dance in the night\n",
      "Their spirits intertwined, forever in flight\n",
      "Whispers of mystery, in the cold night air\n",
      "Moon and raven, a timeless pair\n",
      "\n",
      "Outro:\n",
      "As the night fades away, and the sun starts to rise\n",
      "The moon and raven bid their goodbyes\n",
      "But they'll always be connected, in the depths of the night\n",
      "Moon and raven, a beautiful sight.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "prompt = 'Write a rock song about the Moon and a Raven.'\n",
    "print(llm.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a94d50a4-60ca-4009-a051-b83cf70c7a45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verse 1:\n",
      "Beneath the silver moon's bright glow\n",
      "A raven flies, it's time to show\n",
      "The secrets of the night unfold\n",
      "As the raven's wings take hold\n",
      "\n",
      "Chorus:\n",
      "Moonlight shining through the night\n",
      "Raven's wings take flight\n",
      "In the darkness, they unite\n",
      "A mystical sight, the moon and the raven\n",
      "\n",
      "Verse 2:\n",
      "The raven calls with a haunting cry\n",
      "As the moon watches from the sky\n",
      "Their bond is strong, their spirits free\n",
      "Together they roam, wild and carefree\n",
      "\n",
      "Chorus:\n",
      "Moonlight shining through the night\n",
      "Raven's wings take flight\n",
      "In the darkness, they unite\n",
      "A mystical sight, the moon and the raven\n",
      "\n",
      "Bridge:\n",
      "In the stillness of the night\n",
      "They dance in the pale moonlight\n",
      "A mesmerizing sight to see\n",
      "The moon and the raven, wild and free\n",
      "\n",
      "Chorus:\n",
      "Moonlight shining through the night\n",
      "Raven's wings take flight\n",
      "In the darkness, they unite\n",
      "A mystical sight, the moon and the raven\n",
      "\n",
      "Outro:\n",
      "As the night fades into day\n",
      "The moon and the raven fly away\n",
      "But their bond will never break\n",
      "For in the night, they will awake."
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk.content, end='', flush=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84844cfe-7469-47a6-841c-0fc31d8cdb49",
   "metadata": {},
   "source": [
    "## PromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34389e61-d08b-440a-8a6f-96e99b5bee8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an experienced virologist.\\nWrite a few sentences about the following virus \"hiv\" in german.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Define a template for the prompt\n",
    "template = '''You are an experienced virologist.\n",
    "Write a few sentences about the following virus \"{virus}\" in {language}.'''\n",
    "\n",
    "# Create a PromptTemplate object from the template\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "# Fill in the variable: virus and language\n",
    "prompt = prompt_template.format(virus='hiv', language='german')\n",
    "prompt  # Returns the generated prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "602e2f25-4ba8-4a48-b116-4589af56f9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIV, das humane Immundefizienzvirus, ist ein Retrovirus, das das menschliche Immunsystem schwächt und zu AIDS führen kann. Es wird hauptsächlich durch den Kontakt mit infiziertem Blut, sexuellen Kontakt oder von der Mutter auf das Kind übertragen. Die Behandlung von HIV hat sich in den letzten Jahren erheblich verbessert, aber es gibt immer noch keine Heilung für die Krankheit. Es ist wichtig, sich über die Übertragungswege und Präventionsmaßnahmen von HIV bewusst zu sein, um die Verbreitung der Krankheit einzudämmen.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8084261-b4c6-47e6-8a38-03f339f1f5c5",
   "metadata": {},
   "source": [
    "## ChatPromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fab3930-930d-4c45-a3d8-a6b213d77270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You respond only in the JSON format.'), HumanMessage(content='Top 5 countries in World by population.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# Create a chat template with system and human messages\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content='You respond only in the JSON format.'),\n",
    "        HumanMessagePromptTemplate.from_template('Top {n} countries in {area} by population.')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fill in the specific values for n and area\n",
    "messages = chat_template.format_messages(n='5', area='World')\n",
    "print(messages)  # Outputs the formatted chat messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a768271-ff8d-4d4c-a7c3-21ebed1abd6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"countries\": [\n",
      "        {\n",
      "            \"name\": \"China\",\n",
      "            \"population\": \"1,439,323,776\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"India\",\n",
      "            \"population\": \"1,380,004,385\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"United States\",\n",
      "            \"population\": \"331,002,651\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Indonesia\",\n",
      "            \"population\": \"273,523,615\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Pakistan\",\n",
      "            \"population\": \"220,892,340\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb2eb160-df97-4229-8115-2e8864b400d3",
   "metadata": {},
   "source": [
    "## Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e2aef22-26c3-4e8c-8bbd-99383b6052e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an experience virologist.\n",
      "Write a few sentences about the following virus \"HSV\" in Spanish.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/langchain-pinecone/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "template = '''You are an experience virologist.\n",
    "Write a few sentences about the following virus \"{virus}\" in {language}.'''\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "output = chain.invoke({'virus': 'HSV', 'language': 'Spanish'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "161f079d-a38d-48f5-8466-9b2c185446f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'virus': 'HSV', 'language': 'Spanish', 'text': 'El virus del herpes simple (HSV) es una infección viral común que afecta a millones de personas en todo el mundo. Hay dos tipos de HSV: HSV-1, que suele causar herpes labial, y HSV-2, que suele causar herpes genital. Ambos tipos de virus pueden ser transmitidos a través del contacto directo con una persona infectada, y pueden causar síntomas como ampollas, úlceras y dolor en la piel. Aunque no existe cura para el HSV, existen tratamientos disponibles para controlar los síntomas y prevenir brotes recurrentes.'}\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c23cc0a0-6b02-4007-9192-80f00d7576a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat is the capital of ?. List the top 3 places to visit in that city. Use bullet points\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I'm sorry, but you have not provided the name of the city for which you want to know the capital and top 3 places to visit. Please specify the city so I can provide you with the information you need.\n"
     ]
    }
   ],
   "source": [
    "template = 'What is the capital of {country}?. List the top 3 places to visit in that city. Use bullet points'\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "# Initialize an LLMChain with the ChatOpenAI model and the prompt template\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "country = input('Enter Country: ')\n",
    "\n",
    "# Invoke the chain with specific virus and language values\n",
    "output = chain.invoke(country)\n",
    "print(output['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "963536b8-76e7-4681-bb0d-8309795e2fa3",
   "metadata": {},
   "source": [
    "## Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9e711bc-8bcf-45ce-b993-52e42fb650cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mSure! Here is a simple implementation of linear regression in Python:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "def linear_regression(X, y):\n",
      "    # Calculate the number of data points\n",
      "    n = len(X)\n",
      "    \n",
      "    # Calculate the mean of X and y\n",
      "    mean_X = np.mean(X)\n",
      "    mean_y = np.mean(y)\n",
      "    \n",
      "    # Calculate the slope (m) and y-intercept (b) of the regression line\n",
      "    numerator = np.sum((X - mean_X) * (y - mean_y))\n",
      "    denominator = np.sum((X - mean_X) ** 2)\n",
      "    m = numerator / denominator\n",
      "    b = mean_y - m * mean_X\n",
      "    \n",
      "    return m, b\n",
      "\n",
      "# Example usage\n",
      "X = np.array([1, 2, 3, 4, 5])\n",
      "y = np.array([2, 4, 5, 4, 5])\n",
      "\n",
      "m, b = linear_regression(X, y)\n",
      "print(\"Slope:\", m)\n",
      "print(\"Y-intercept:\", b)\n",
      "```\n",
      "\n",
      "This function takes in two arrays X and y, where X represents the independent variable and y represents the dependent variable. It calculates the slope and y-intercept of the regression line that best fits the data points using the least squares method.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe provided Python function, `linear_regression(X, y)`, is an implementation of simple linear regression using the method of least squares. Linear regression is a fundamental statistical approach for modeling the relationship between an independent variable (or variables, in the case of multiple regression) and a dependent variable. This particular function assumes a single independent variable, making it a model for simple linear regression. The relationship is modeled through a straight line with the equation \\(y = mx + b\\), where:\n",
      "\n",
      "- \\(y\\) is the estimated dependent variable (target),\n",
      "- \\(x\\) is the independent variable (predictor),\n",
      "- \\(m\\) is the slope of the regression line (representing the change in \\(y\\) for a one-unit change in \\(x\\)),\n",
      "- \\(b\\) is the y-intercept (the value of \\(y\\) when \\(x = 0\\)).\n",
      "\n",
      "Here's a detailed explanation of each step in the function:\n",
      "\n",
      "### Import Necessary Library\n",
      "- The function begins by importing NumPy, which is a popular Python library for numerical computations. NumPy provides efficient ways to work with arrays and matrices, making it ideal for linear algebra operations, which are essential in the calculation of linear regression parameters.\n",
      "\n",
      "### The `linear_regression` Function\n",
      "- The function `linear_regression(X, y)` takes two parameters:\n",
      "  - `X`, which is a NumPy array representing the dataset's independent variable values.\n",
      "  - `y`, which is a NumPy array representing the dependent variable values corresponding to each `X` value.\n",
      "\n",
      "#### Calculating the Number of Data Points\n",
      "- The function starts by determining the number of data points (samples), using `len(X)`. This count, however, is not utilized in further calculations within this simple implementation.\n",
      "\n",
      "#### Calculating Mean of `X` and `y`\n",
      "- It computes the mean (average) of the `X` values using `np.mean(X)` and the mean of `y` values using `np.mean(y)`. These mean values are used to establish the relationship line's best fit by minimizing the sum of squares of vertical distances from the observed points to the regression line.\n",
      "\n",
      "#### Calculating Slope (`m`) and Y-intercept (`b`)\n",
      "- The core of the function involves calculating the slope (`m`) of the regression line. This is done by using the formula \n",
      "\\[m = \\frac{\\Sigma((X - mean_X) \\times (y - mean_y))}{\\Sigma((X - mean_X)^2)}\\]\n",
      "  - This operation leverages vectorized computation (thanks to NumPy) for efficiency, computing the numerator as `np.sum((X - mean_X) * (y - mean_y))` and the denominator as `np.sum((X - mean_X) ** 2)`. The slope `m` is then the numerator divided by the denominator.\n",
      "- Following that, the y-intercept (`b`) of the regression line is calculated with the formula \n",
      "\\[b = mean_y - m \\times mean_X\\]\n",
      "  - This represents the point where the regression line crosses the y-axis.\n",
      "\n",
      "### Returning the Result\n",
      "- Finally, the function returns the calculated slope (`m`) and y-intercept (`b`) of the regression line, which fully defines the line that best fits the given data according to the least squares criterion.\n",
      "\n",
      "### Example Usage\n",
      "- The example usage creates an array `X` as the independent variable and `y` as the dependent variable. It then calls `linear_regression(X, y)` to compute the slope and intercept of the best-fit line, printing these values out.\n",
      "- In this example, with `X = np.array([1, 2, 3, 4, 5])` and `y = np.array([2, 4, 5, 4, 5])`, the function calculates and prints the slope and y-intercept that define the best-fit line according to linear regression.\n",
      "\n",
      "The methodology implicitly assumes a linear relationship between the independent and dependent variables. It provides a straightforward way of understanding the directional relationship (positive or negative) and strength (magnitude of the slope) between variables, commonly used across numerous disciplines for prediction, trend analysis, and data exploration.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "# Initialize the first ChatOpenAI model (gpt-3.5-turbo) with specific temperature\n",
    "llm1 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
    "\n",
    "# Define the first prompt template\n",
    "prompt_template1 = PromptTemplate.from_template(\n",
    "    template='You are an experienced scientist and Python programmer. Write a function that implements the concept of {concept}.'\n",
    ")\n",
    "# Create an LLMChain using the first model and the prompt template\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt_template1)\n",
    "\n",
    "# Initialize the second ChatOpenAI model (gpt-4-turbo) with specific temperature\n",
    "llm2 = ChatOpenAI(model_name='gpt-4-turbo-preview', temperature=1.2)\n",
    "\n",
    "# Define the second prompt template\n",
    "prompt_template2 = PromptTemplate.from_template(\n",
    "    template='Given the Python function {function}, describe it as detailed as possible.'\n",
    ")\n",
    "# Create another LLMChain using the second model and the prompt template\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt_template2)\n",
    "\n",
    "# Combine both chains into a SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "\n",
    "# Invoke the overall chain with the concept \"linear regression\"\n",
    "output = overall_chain.invoke('linear regression')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b365ca5e-84f6-484f-829b-1ba9ff9798e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided Python function, `linear_regression(X, y)`, is an implementation of simple linear regression using the method of least squares. Linear regression is a fundamental statistical approach for modeling the relationship between an independent variable (or variables, in the case of multiple regression) and a dependent variable. This particular function assumes a single independent variable, making it a model for simple linear regression. The relationship is modeled through a straight line with the equation \\(y = mx + b\\), where:\n",
      "\n",
      "- \\(y\\) is the estimated dependent variable (target),\n",
      "- \\(x\\) is the independent variable (predictor),\n",
      "- \\(m\\) is the slope of the regression line (representing the change in \\(y\\) for a one-unit change in \\(x\\)),\n",
      "- \\(b\\) is the y-intercept (the value of \\(y\\) when \\(x = 0\\)).\n",
      "\n",
      "Here's a detailed explanation of each step in the function:\n",
      "\n",
      "### Import Necessary Library\n",
      "- The function begins by importing NumPy, which is a popular Python library for numerical computations. NumPy provides efficient ways to work with arrays and matrices, making it ideal for linear algebra operations, which are essential in the calculation of linear regression parameters.\n",
      "\n",
      "### The `linear_regression` Function\n",
      "- The function `linear_regression(X, y)` takes two parameters:\n",
      "  - `X`, which is a NumPy array representing the dataset's independent variable values.\n",
      "  - `y`, which is a NumPy array representing the dependent variable values corresponding to each `X` value.\n",
      "\n",
      "#### Calculating the Number of Data Points\n",
      "- The function starts by determining the number of data points (samples), using `len(X)`. This count, however, is not utilized in further calculations within this simple implementation.\n",
      "\n",
      "#### Calculating Mean of `X` and `y`\n",
      "- It computes the mean (average) of the `X` values using `np.mean(X)` and the mean of `y` values using `np.mean(y)`. These mean values are used to establish the relationship line's best fit by minimizing the sum of squares of vertical distances from the observed points to the regression line.\n",
      "\n",
      "#### Calculating Slope (`m`) and Y-intercept (`b`)\n",
      "- The core of the function involves calculating the slope (`m`) of the regression line. This is done by using the formula \n",
      "\\[m = \\frac{\\Sigma((X - mean_X) \\times (y - mean_y))}{\\Sigma((X - mean_X)^2)}\\]\n",
      "  - This operation leverages vectorized computation (thanks to NumPy) for efficiency, computing the numerator as `np.sum((X - mean_X) * (y - mean_y))` and the denominator as `np.sum((X - mean_X) ** 2)`. The slope `m` is then the numerator divided by the denominator.\n",
      "- Following that, the y-intercept (`b`) of the regression line is calculated with the formula \n",
      "\\[b = mean_y - m \\times mean_X\\]\n",
      "  - This represents the point where the regression line crosses the y-axis.\n",
      "\n",
      "### Returning the Result\n",
      "- Finally, the function returns the calculated slope (`m`) and y-intercept (`b`) of the regression line, which fully defines the line that best fits the given data according to the least squares criterion.\n",
      "\n",
      "### Example Usage\n",
      "- The example usage creates an array `X` as the independent variable and `y` as the dependent variable. It then calls `linear_regression(X, y)` to compute the slope and intercept of the best-fit line, printing these values out.\n",
      "- In this example, with `X = np.array([1, 2, 3, 4, 5])` and `y = np.array([2, 4, 5, 4, 5])`, the function calculates and prints the slope and y-intercept that define the best-fit line according to linear regression.\n",
      "\n",
      "The methodology implicitly assumes a linear relationship between the independent and dependent variables. It provides a straightforward way of understanding the directional relationship (positive or negative) and strength (magnitude of the slope) between variables, commonly used across numerous disciplines for prediction, trend analysis, and data exploration.\n"
     ]
    }
   ],
   "source": [
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9b9413-9d79-47e4-8464-40cb3756700e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[13, 26, 39, 52, 65, 78, 91]\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run('print([n for n in range(1, 100) if n % 13 == 0])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9973644c-65a3-44ac-ac9e-1be39950acdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo solve this, I need to calculate the factorial of 12 first, then find its square root, and finally format the result to display it with 4 decimal points. I can use the `math` module in Python for both the factorial and square root calculations, and then format the output as required.\n",
      "Action: Python_REPL\n",
      "Action Input: import math\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that the math module is imported, I can proceed to calculate the factorial of 12.\n",
      "Action: Python_REPL\n",
      "Action Input: factorial_12 = math.factorial(12)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the factorial of 12. Next, I need to calculate the square root of this value.\n",
      "Action: Python_REPL\n",
      "Action Input: sqrt_factorial_12 = math.sqrt(factorial_12)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have calculated the square root of the factorial of 12. Now, I need to format this result to display it with 4 decimal points.\n",
      "Action: Python_REPL\n",
      "Action Input: print(f\"{sqrt_factorial_12:.4f}\")\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m21886.1052\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 21886.1052\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Calculate the square root of the factorial of 12 and display it with 4 decimal points',\n",
       " 'output': '21886.1052'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the ChatOpenAI model with gpt-4-turbo and a temperature of 0\n",
    "llm = ChatOpenAI(model='gpt-4-turbo-preview', temperature=0)\n",
    "\n",
    "# Create a Python agent using the ChatOpenAI model and a PythonREPLTool\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Invoke the agent\n",
    "prompt = 'Calculate the square root of the factorial of 12 and display it with 4 decimal points'\n",
    "agent_executor.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a1046e3-42dd-41a1-be25-8f48454f92f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate 5.1 raised to the power of 7.3 to get the answer.\n",
      "Action: Python_REPL\n",
      "Action Input: print(5.1 ** 7.3)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 146306.05007233328\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke('What is the answer to 5.1 ** 7.3?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af92f7d0-06c4-475e-9deb-8ab0352050ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the answer to 5.1 ** 7.3?', 'output': '146306.05007233328'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e936c363-5720-443b-b4f9-29d0b5263536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the answer to 5.1 ** 7.3?\n"
     ]
    }
   ],
   "source": [
    "print(response['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1accfc09-b6c0-4c0a-8cc6-54590d081f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146306.05007233328\n"
     ]
    }
   ],
   "source": [
    "print(response['output'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec1e575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
