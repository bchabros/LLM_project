{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3252a1e4-e2c1-4d84-8c34-c5ac069ad101",
   "metadata": {},
   "source": [
    "# LangChain Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec66eb5-5981-4670-8bea-3943bb61a885",
   "metadata": {},
   "source": [
    "### Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bc48d-40a1-4042-bc88-e115d83fbf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ./requirements.txt -q\n",
    "# !pip install from base env\n",
    "# pip install from virtual env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "601b4ba4-86da-483f-81ef-f71727f456c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.0.335\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/anaconda3/envs/LLM/lib/python3.9/site-packages\n",
      "Requires: aiohttp, anyio, async-timeout, dataclasses-json, jsonpatch, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bf26d04-ea30-411e-a601-6988114c0fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 0.28.1\n",
      "Summary: Python client library for the OpenAI API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: OpenAI\n",
      "Author-email: support@openai.com\n",
      "License: \n",
      "Location: /opt/anaconda3/envs/LLM/lib/python3.9/site-packages\n",
      "Requires: aiohttp, requests, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849d8fea-5b48-498e-bedb-3b889848e95b",
   "metadata": {},
   "source": [
    "### Python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea3ea8fa-8d97-4100-9273-a9d83b8e2500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Chabi/Documents/LLM_project/LangChain_Pinecone_OpenAI/LangChain_Pinecone'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b45adbb0-bd27-4a19-9d52-e5a7839a8d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 48\n",
      "drwxr-xr-x  6 Chabi  staff    192 Nov 15 19:52 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxr-xr-x  4 Chabi  staff    128 Nov 14 21:13 \u001b[34m..\u001b[m\u001b[m\n",
      "-rw-r--r--@ 1 Chabi  staff    151 Nov 15 19:03 .env\n",
      "drwxr-xr-x  4 Chabi  staff    128 Nov 15 18:56 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\n",
      "-rw-r--r--  1 Chabi  staff  12589 Nov 15 19:52 01_LangChain_Basic.ipynb\n",
      "-rw-r--r--  1 Chabi  staff     57 Nov 14 21:20 requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ffe7ee5-306c-4c54-a2c8-944b80dea7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be5aa68b-4dbb-4482-bd20-5813700f60d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2f71515a-b1c2-4bd4-b208-cf4f19e7b543'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c11037-be61-459f-a22d-3f1796ae61f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c84d7-d780-439b-b939-b9a4218cc255",
   "metadata": {},
   "source": [
    "### LLM Models (Wrappers): GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2acecf5f-cac2-4b1c-8e13-5743de545b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63bf0f79-7746-4108-84ba-58c60275d7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.7, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'logit_bias': {}, 'max_tokens': 512}\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name='text-davinci-003',\n",
    "             temperature=0.7,\n",
    "             max_tokens=512)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31e4c90e-b703-46d4-9a62-b229043cc2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Quantum mechanics is the study of the behavior of matter and energy at the atomic and subatomic level, where particles have wave-like properties.\n"
     ]
    }
   ],
   "source": [
    "output = llm('explain quantum mechanics in one sentence')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20c7f0bd-6f0d-4ebb-a342-6690f2b203e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(llm.get_num_tokens('explain quantum mechanics in one sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54f1559f-c667-4dc8-ba6d-168f839f6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate(['... is the capital of France.', \n",
    "                       'What is the formula for the area of a circle?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9d9a89a-f095-479a-b040-f83810931058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Generation(text='\\n\\nParis', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThe formula for the area of a circle is A = πr^2, where r is the radius of the circle.', generation_info={'finish_reason': 'stop', 'logprobs': None})]]\n"
     ]
    }
   ],
   "source": [
    "print(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd29b9e2-8fe2-43b8-aa94-172d1bdee0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The formula for the area of a circle is A = πr^2, where r is the radius of the circle.\n"
     ]
    }
   ],
   "source": [
    "print(output.generations[1][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5922f328-1cd3-4cec-be60-4d0b9e64c07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0928ea1e-eafa-4240-8706-064ef0a833cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate(['Write an original tagline for burger restaurant'] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de611bad-3ab2-4717-b03a-f333aa9793af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='\\n\\n\"Taste the flame-grilled flavor of our burgers!\"', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\n\"A Burger for Every Taste - Our Burgers Will Satisfy Your Craving!\"', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\n\"Taste the Difference: Fresh Burgers at Our Grill!\"', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'prompt_tokens': 24, 'total_tokens': 73, 'completion_tokens': 49}, 'model_name': 'text-davinci-003'} run=[RunInfo(run_id=UUID('d5129bfd-8614-4280-bf49-c5e529e38bc4')), RunInfo(run_id=UUID('0e930e9f-c850-4669-b2e2-f1ebf0ee590f')), RunInfo(run_id=UUID('9ddd66f6-c953-4daa-bee0-af24705c0e74'))]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "676d2014-1f71-444f-bdfe-f0c961f3245c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Taste the flame-grilled flavor of our burgers!\"\n",
      "\n",
      "\"A Burger for Every Taste - Our Burgers Will Satisfy Your Craving!\"\n",
      "\n",
      "\"Taste the Difference: Fresh Burgers at Our Grill!\""
     ]
    }
   ],
   "source": [
    "for o in output.generations:\n",
    "    print(o[0].text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b15d45-c3c6-4adb-9c9e-5ffeaac8c015",
   "metadata": {},
   "source": [
    "### ChatModels:GPT-3.5-Trubo and GPT-4\n",
    "\n",
    "https://platform.openai.com/docs/api-reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5753e3c1-79c0-4673-aa06-66e6cef1f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage,HumanMessage, SystemMessage\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a3cba9d-47e0-4ecf-9c27-657961616971",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model='gpt-3.5-turbo',\n",
    "                  temperature=0.5,\n",
    "                  max_tokens=1024)\n",
    "messages = [\n",
    "    SystemMessage(content='You are a physicist and respond only in Polish.'),\n",
    "    HumanMessage(content='Explain quantum mechanics in one sentence.')\n",
    "]\n",
    "output = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9287f54f-0152-44d6-b40c-ba733405cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Mechanika kwantowa jest teorią opisującą zachowanie się cząstek na bardzo małych skalach, gdzie obowiązują zasady superpozycji i nieoznaczoności.'\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34d770db-6898-412f-a26a-eaf833636fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mechanika kwantowa jest teorią opisującą zachowanie się cząstek na bardzo małych skalach, gdzie obowiązują zasady superpozycji i nieoznaczoności.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40fcf55-453a-4627-b8a5-fd29141d843a",
   "metadata": {},
   "source": [
    "### Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22075bb5-75f7-4bd2-968e-85b556d607f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e50f5565-b5d3-4c63-a259-b9930cd122be",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''You are an experienced virologist.\n",
    "Write a few senrences about the following {virus} in {language}.'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus', 'language'],\n",
    "    template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad909cb7-e0de-4a2e-9efc-2b9b3760d7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language', 'virus'] template='You are an experienced virologist.\\nWrite a few senrences about the following {virus} in {language}.'\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7746177a-ffd7-4412-9f99-288b4a97abfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Ebola to zakażna choroba wywoływana przez wirusa Eboli, który może powodować ciężkie objawy i śmierć. Jest szczególnie niebezpieczny dla ludzi, gdyż może szybko się rozprzestrzeniać. Może być przenoszona przez kontakt z krwią, wydzielinami lub innymi tkankami ofiary.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model='text-davinci-003',\n",
    "             temperature=0.7)\n",
    "output = llm(prompt.format(virus='ebola',\n",
    "                           language='polish'))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84ce3120-154b-4a55-806b-a4ec361c7d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "HIV jest wirusową chorobą zakaźną, która atakuje układ odpornościowy człowieka. Może ona powodować AIDS, które ma katastrofalne skutki dla zdrowia i życia człowieka. Dlatego ważne jest, aby wiedzieć o HIV i stosować środki ostrożności, aby zapobiec jego rozprzestrzenianiu się.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model='text-davinci-003',\n",
    "             temperature=0.7)\n",
    "output = llm(prompt.format(virus='HIV',\n",
    "                           language='polish'))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b95ece-93ca-4962-868a-26817bd2e9d5",
   "metadata": {},
   "source": [
    "### Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5525040e-cc7c-44bf-8590-7383c173b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "999830e7-6378-4e6d-9c9f-e6f28b8acba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-3.5-turbo',\n",
    "                 temperature=0.5)\n",
    "\n",
    "template = '''You are an experienced data scientist .\n",
    "Write a few sentences about the following {case} in {language}.'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['case', 'language'],\n",
    "    template=template)\n",
    "\n",
    "chain = LLMChain(llm=llm,\n",
    "                 prompt=prompt)\n",
    "\n",
    "output = chain.run({'case': 'overfitting',\n",
    "                   'language': 'Polish'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "096bd78d-13b1-4a27-b645-e2090c4540bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfitting, po polsku nazywane nadmiernym dopasowaniem, jest zjawiskiem występującym w uczeniu maszynowym, gdy model jest zbyt dokładnie dopasowany do danych treningowych. Oznacza to, że model zbyt mocno \"zapamiętuje\" dane treningowe, co prowadzi do słabej generalizacji na nowe dane. Nadmierne dopasowanie może być problematyczne, ponieważ może prowadzić do błędnych prognoz i niskiej wydajności na danych testowych. Istnieją różne metody i techniki, takie jak regularyzacja, zbiór walidacyjny i cross-validation, które mogą pomóc w radzeniu sobie z nadmiernym dopasowaniem.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8652c8-fbc1-486a-a12a-94d60cc37775",
   "metadata": {},
   "source": [
    "### Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "533dd78b-c8c4-4529-9dba-96fcb39d5b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f773c8d4-3c85-4fd6-842b-6469dc5f38e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm1 = OpenAI(model='text-davinci-003', \n",
    "              temperature=0.7,\n",
    "              max_tokens=1024)\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=['concept'],\n",
    "    template='''You are an expierenced scientist and Python programmer.\n",
    "        Write a function that implements the concept of {concpet}.''')\n",
    "chain1 = LLMChain(llm=llm1,\n",
    "                  prompt=prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "401bd5d2-ea0a-470d-9787-fff1d38fc1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2 = ChatOpenAI(model='gpt-3.5-turbo',\n",
    "                  temperature=1.2)\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['function'],\n",
    "    template='Give the Python function {function}, describe it as detailed as possible.')\n",
    "chain2 = LLMChain(llm=llm2,\n",
    "                  prompt=prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ee630b82-dc5f-4c33-9516-0204d8e7611e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "def random_forest(X,y,n_estimators=10):\n",
      "    \"\"\"\n",
      "    This function implements the concept of a random forest.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X: a numpy array of shape (n_samples, n_features)\n",
      "        Training data \n",
      "    y: a numpy array of shape (n_samples,)\n",
      "        Target values\n",
      "    n_estimators: int, optional (default=10)\n",
      "        Number of trees in the forest\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    forest: a list of DecisionTreeClassifier \n",
      "        The random forest of decision tree classifiers\n",
      "    \"\"\"\n",
      "    \n",
      "    forest = []\n",
      "    for _ in range(n_estimators):\n",
      "        sample_indices = np.random.choice(range(X.shape[0]), X.shape[0], replace=True)\n",
      "        X_sample = X[sample_indices]\n",
      "        y_sample = y[sample_indices]\n",
      "        tree = DecisionTreeClassifier(random_state=0)\n",
      "        tree.fit(X_sample, y_sample)\n",
      "        forest.append(tree)\n",
      "    return forest\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe `random_forest` function in Python implements the concept of a random forest. \n",
      "\n",
      "The function takes three parameters:\n",
      "- `X`: A numpy array of shape `(n_samples, n_features)` that represents the training data. Each row in the array corresponds to a sample, and each column represents a feature.\n",
      "- `y`: A numpy array of shape `(n_samples,)` that represents the target values for the training data.\n",
      "- `n_estimators`: An integer, optional parameter, with a default value of `10`. This parameter specifies the number of trees in the random forest.\n",
      "\n",
      "The function returns a list of `DecisionTreeClassifier` objects, which represents the random forest of decision tree classifiers.\n",
      "\n",
      "The function starts by initializing an empty list named `forest`.\n",
      "\n",
      "Then, it enters a loop that runs `n_estimators` times. In each iteration of the loop, it follows these steps:\n",
      "\n",
      "1. Randomly selects `X.shape[0]` indices from range `0` to `X.shape[0]`. This means it randomly selects the indices with replacement. The indices are stored in the `sample_indices` variable.\n",
      "2. Uses the sampled indices to create a new training data subset `X_sample` by indexing the original `X` array using the `sample_indices`.\n",
      "3. Uses the sampled indices to create a new target values subset `y_sample` by indexing the original `y` array using the `sample_indices`.\n",
      "4. Initializes a `DecisionTreeClassifier` object called `tree` with a random state of `0`.\n",
      "5. Fits the `tree` using `X_sample` and `y_sample`.\n",
      "6. Appends the trained `tree` to the `forest` list.\n",
      "\n",
      "After the loop finishes, the function returns the `forest` list, which contains the trained decision tree classifiers forming the random forest.\n",
      "\n",
      "In summary, the `random_forest` function creates a random forest by training `n_estimators` decision trees on random subsets of the training data.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "output = overall_chain.run('random forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d1d92-ebc4-428e-92fa-cf136ef83710",
   "metadata": {},
   "source": [
    "### LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c30eb2c-dc44-4ac8-8c65-637f9d070077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonAstREPLTool\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bf9f4e5-4167-43b2-b237-e4d128394d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to calculate the factorial of 20 and then take the square root of that number.\n",
      "Action: python_repl_ast\n",
      "Action Input: from math import factorial; print(round(factorial(20)**0.5, 4))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1559776268.6285\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 1559776268.6285\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1559776268.6285'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonAstREPLTool(), # explain everythink into python code\n",
    "    verbose=True)\n",
    "agent_executor.run('Calculate the square root of the factorial of 20 and display it with four decimal points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "621114e7-5714-4ffd-8fa6-e0f6666c6c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1559776268.6285\n"
     ]
    }
   ],
   "source": [
    "from math import factorial\n",
    "print(round(factorial(20)**0.5, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3029d852-dccb-48b2-a8b9-ebc58dbdfe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to use the python REPL to calculate this\n",
      "Action: python_repl_ast\n",
      "Action Input: 5.1 ** 7.3\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 146306.05007233328\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the answer to 5.1 ** 7.3?', 'output': '146306.05007233328'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor('what is the answer to 5.1 ** 7.3?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c1629-87e3-4c47-8dfc-975f20dd6cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
